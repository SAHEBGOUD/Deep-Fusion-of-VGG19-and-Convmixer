{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c18422be-e308-48bb-8aec-64f5fe9bdb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: torch in c:\\users\\admin\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow torch torchvision scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa2ff60a-7620-4eed-ab4e-3e5e33da119b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m579s\u001b[0m 4s/step - accuracy: 0.5111 - loss: 1.4091 - val_accuracy: 0.6799 - val_loss: 0.7344\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m582s\u001b[0m 5s/step - accuracy: 0.7257 - loss: 0.6228 - val_accuracy: 0.7798 - val_loss: 0.5581\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m595s\u001b[0m 4s/step - accuracy: 0.8410 - loss: 0.4395 - val_accuracy: 0.8312 - val_loss: 0.4516\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 4s/step - accuracy: 0.8816 - loss: 0.3393 - val_accuracy: 0.8235 - val_loss: 0.4194\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 4s/step - accuracy: 0.9123 - loss: 0.2573 - val_accuracy: 0.9011 - val_loss: 0.2839\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m561s\u001b[0m 4s/step - accuracy: 0.9597 - loss: 0.1797 - val_accuracy: 0.9282 - val_loss: 0.2389\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m583s\u001b[0m 5s/step - accuracy: 0.9746 - loss: 0.1269 - val_accuracy: 0.9370 - val_loss: 0.2065\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m563s\u001b[0m 4s/step - accuracy: 0.9792 - loss: 0.1039 - val_accuracy: 0.9399 - val_loss: 0.1808\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m551s\u001b[0m 4s/step - accuracy: 0.9873 - loss: 0.0794 - val_accuracy: 0.9496 - val_loss: 0.1687\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 4s/step - accuracy: 0.9898 - loss: 0.0635 - val_accuracy: 0.9379 - val_loss: 0.1757\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 3s/step - accuracy: 0.9436 - loss: 0.1626\n",
      "Validation Accuracy: 93.79%\n"
     ]
    }
   ],
   "source": [
    "#VGG16\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, Xception, InceptionV3, EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build and compile a model using a pre-trained CNN\n",
    "def build_model(base_model_fn, preprocess_fn, img_size=IMG_SIZE):\n",
    "    # Load the pre-trained model\n",
    "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=img_size + (3,))\n",
    "    \n",
    "    # Freeze the pre-trained model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=img_size + (3,)),\n",
    "        tf.keras.layers.Lambda(preprocess_fn),  # Preprocessing specific to the model\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),  # Use Global Average Pooling instead of Flatten for better generalization\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Choose a pre-trained model (you can switch between these models)\n",
    "model_name = 'VGG16'  # Options: 'VGG16', 'ResNet50', 'Xception', 'InceptionV3', 'EfficientNetB0'\n",
    "\n",
    "if model_name == 'VGG16':\n",
    "    model = build_model(VGG16, vgg16_preprocess)\n",
    "elif model_name == 'ResNet50':\n",
    "    model = build_model(ResNet50, resnet50_preprocess)\n",
    "elif model_name == 'Xception':\n",
    "    model = build_model(Xception, xception_preprocess)\n",
    "elif model_name == 'InceptionV3':\n",
    "    model = build_model(InceptionV3, inception_preprocess)\n",
    "elif model_name == 'EfficientNetB0':\n",
    "    model = build_model(EfficientNetB0, efficientnet_preprocess)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09794dc-cdf4-4abb-a17c-8a382fb7c2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 4s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.87      0.98      0.92       246\n",
      "          CI       0.95      0.96      0.96       503\n",
      "          CN       0.99      0.86      0.92       282\n",
      "\n",
      "    accuracy                           0.94      1031\n",
      "   macro avg       0.94      0.93      0.93      1031\n",
      "weighted avg       0.94      0.94      0.94      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8394caf1-232a-47e0-b246-30df958013d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 2s/step - accuracy: 0.4766 - loss: 1.2541 - val_accuracy: 0.5626 - val_loss: 0.8698\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - accuracy: 0.6732 - loss: 0.7762 - val_accuracy: 0.7032 - val_loss: 0.7182\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 1s/step - accuracy: 0.7423 - loss: 0.6631 - val_accuracy: 0.7565 - val_loss: 0.6113\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 1s/step - accuracy: 0.7728 - loss: 0.5723 - val_accuracy: 0.7546 - val_loss: 0.6070\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 1s/step - accuracy: 0.8099 - loss: 0.4907 - val_accuracy: 0.7983 - val_loss: 0.5353\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 1s/step - accuracy: 0.8457 - loss: 0.4314 - val_accuracy: 0.8516 - val_loss: 0.4160\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 2s/step - accuracy: 0.8910 - loss: 0.3376 - val_accuracy: 0.8235 - val_loss: 0.4189\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 1s/step - accuracy: 0.8986 - loss: 0.3107 - val_accuracy: 0.8720 - val_loss: 0.3428\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 2s/step - accuracy: 0.9234 - loss: 0.2507 - val_accuracy: 0.8594 - val_loss: 0.3750\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 2s/step - accuracy: 0.9313 - loss: 0.2306 - val_accuracy: 0.8904 - val_loss: 0.2714\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.8816 - loss: 0.2775\n",
      "Validation Accuracy: 89.04%\n"
     ]
    }
   ],
   "source": [
    "#Resnet50\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, Xception, InceptionV3, EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset manually and split it into train/validation sets\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build and compile a model using a pre-trained CNN\n",
    "def build_model(base_model_fn, preprocess_fn, img_size=IMG_SIZE):\n",
    "    # Load the pre-trained model\n",
    "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=img_size + (3,))\n",
    "    \n",
    "    # Freeze the pre-trained model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=img_size + (3,)),\n",
    "        tf.keras.layers.Lambda(preprocess_fn),  # Preprocessing specific to the model\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),  # Use Global Average Pooling instead of Flatten for better generalization\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Choose a pre-trained model (you can switch between these models)\n",
    "model_name = 'ResNet50'  # Options: 'VGG16', 'ResNet50', 'Xception', 'InceptionV3', 'EfficientNetB0'\n",
    "\n",
    "if model_name == 'VGG16':\n",
    "    model = build_model(VGG16, vgg16_preprocess)\n",
    "elif model_name == 'ResNet50':\n",
    "    model = build_model(ResNet50, resnet50_preprocess)\n",
    "elif model_name == 'Xception':\n",
    "    model = build_model(Xception, xception_preprocess)\n",
    "elif model_name == 'InceptionV3':\n",
    "    model = build_model(InceptionV3, inception_preprocess)\n",
    "elif model_name == 'EfficientNetB0':\n",
    "    model = build_model(EfficientNetB0, efficientnet_preprocess)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5be09732-522e-4bfa-a526-b3baf2b46613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.98      0.78      0.87       228\n",
      "          CI       0.86      0.99      0.92       515\n",
      "          CN       0.91      0.81      0.86       288\n",
      "\n",
      "    accuracy                           0.89      1031\n",
      "   macro avg       0.91      0.86      0.88      1031\n",
      "weighted avg       0.90      0.89      0.89      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15986030-03db-4e1b-aaf8-ca8931f73e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 2s/step - accuracy: 0.4863 - loss: 1.0502 - val_accuracy: 0.5742 - val_loss: 0.8899\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m288s\u001b[0m 2s/step - accuracy: 0.6151 - loss: 0.8500 - val_accuracy: 0.6596 - val_loss: 0.7975\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 2s/step - accuracy: 0.6674 - loss: 0.7512 - val_accuracy: 0.6770 - val_loss: 0.7486\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 2s/step - accuracy: 0.7015 - loss: 0.6993 - val_accuracy: 0.7032 - val_loss: 0.6959\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 2s/step - accuracy: 0.7321 - loss: 0.6517 - val_accuracy: 0.7468 - val_loss: 0.6337\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m254s\u001b[0m 2s/step - accuracy: 0.7651 - loss: 0.5905 - val_accuracy: 0.7371 - val_loss: 0.6261\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m249s\u001b[0m 2s/step - accuracy: 0.7703 - loss: 0.5611 - val_accuracy: 0.7711 - val_loss: 0.5498\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 2s/step - accuracy: 0.8101 - loss: 0.5003 - val_accuracy: 0.7604 - val_loss: 0.5674\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 2s/step - accuracy: 0.8219 - loss: 0.4640 - val_accuracy: 0.7265 - val_loss: 0.5977\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 2s/step - accuracy: 0.8254 - loss: 0.4355 - val_accuracy: 0.8167 - val_loss: 0.4566\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - accuracy: 0.8361 - loss: 0.4388\n",
      "Validation Accuracy: 81.67%\n"
     ]
    }
   ],
   "source": [
    "#Xception\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, Xception, InceptionV3, EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset manually and split it into train/validation sets\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build and compile a model using a pre-trained CNN\n",
    "def build_model(base_model_fn, preprocess_fn, img_size=IMG_SIZE):\n",
    "    # Load the pre-trained model\n",
    "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=img_size + (3,))\n",
    "    \n",
    "    # Freeze the pre-trained model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=img_size + (3,)),\n",
    "        tf.keras.layers.Lambda(preprocess_fn),  # Preprocessing specific to the model\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),  # Use Global Average Pooling instead of Flatten for better generalization\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Choose a pre-trained model (you can switch between these models)\n",
    "model_name = 'Xception'  # Options: 'VGG16', 'ResNet50', 'Xception', 'InceptionV3', 'EfficientNetB0'\n",
    "\n",
    "if model_name == 'VGG16':\n",
    "    model = build_model(VGG16, vgg16_preprocess)\n",
    "elif model_name == 'ResNet50':\n",
    "    model = build_model(ResNet50, resnet50_preprocess)\n",
    "elif model_name == 'Xception':\n",
    "    model = build_model(Xception, xception_preprocess)\n",
    "elif model_name == 'InceptionV3':\n",
    "    model = build_model(InceptionV3, inception_preprocess)\n",
    "elif model_name == 'EfficientNetB0':\n",
    "    model = build_model(EfficientNetB0, efficientnet_preprocess)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f12587-d199-420a-87aa-d04471b9fb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 2s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.87      0.55      0.67       210\n",
      "          CI       0.80      0.93      0.86       515\n",
      "          CN       0.82      0.81      0.82       306\n",
      "\n",
      "    accuracy                           0.82      1031\n",
      "   macro avg       0.83      0.76      0.78      1031\n",
      "weighted avg       0.82      0.82      0.81      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccc019d7-e99a-4494-8f3d-861ed44efb3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 434ms/step - accuracy: 0.5247 - loss: 0.9771 - val_accuracy: 0.6159 - val_loss: 0.8177\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 510ms/step - accuracy: 0.6594 - loss: 0.7800 - val_accuracy: 0.7236 - val_loss: 0.7114\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 488ms/step - accuracy: 0.7039 - loss: 0.6939 - val_accuracy: 0.7565 - val_loss: 0.6439\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 508ms/step - accuracy: 0.7573 - loss: 0.6155 - val_accuracy: 0.7905 - val_loss: 0.5728\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 501ms/step - accuracy: 0.7786 - loss: 0.5559 - val_accuracy: 0.7420 - val_loss: 0.5768\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 498ms/step - accuracy: 0.7938 - loss: 0.5111 - val_accuracy: 0.8361 - val_loss: 0.4646\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 493ms/step - accuracy: 0.8150 - loss: 0.4665 - val_accuracy: 0.8109 - val_loss: 0.4667\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 499ms/step - accuracy: 0.8423 - loss: 0.4076 - val_accuracy: 0.8623 - val_loss: 0.3936\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 496ms/step - accuracy: 0.8491 - loss: 0.3935 - val_accuracy: 0.8778 - val_loss: 0.3418\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 480ms/step - accuracy: 0.8735 - loss: 0.3423 - val_accuracy: 0.8914 - val_loss: 0.3262\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 385ms/step - accuracy: 0.8781 - loss: 0.3496\n",
      "Validation Accuracy: 89.14%\n"
     ]
    }
   ],
   "source": [
    "#EfficientNetB0\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, Xception, InceptionV3, EfficientNetB0\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet50_preprocess\n",
    "from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset manually and split it into train/validation sets\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build and compile a model using a pre-trained CNN\n",
    "def build_model(base_model_fn, preprocess_fn, img_size=IMG_SIZE):\n",
    "    # Load the pre-trained model\n",
    "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=img_size + (3,))\n",
    "    \n",
    "    # Freeze the pre-trained model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=img_size + (3,)),\n",
    "        tf.keras.layers.Lambda(preprocess_fn),  # Preprocessing specific to the model\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),  # Use Global Average Pooling instead of Flatten for better generalization\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Choose a pre-trained model (you can switch between these models)\n",
    "model_name = 'EfficientNetB0'  # Options: 'VGG16', 'ResNet50', 'Xception', 'InceptionV3', 'EfficientNetB0'\n",
    "\n",
    "if model_name == 'VGG16':\n",
    "    model = build_model(VGG16, vgg16_preprocess)\n",
    "elif model_name == 'ResNet50':\n",
    "    model = build_model(ResNet50, resnet50_preprocess)\n",
    "elif model_name == 'Xception':\n",
    "    model = build_model(Xception, xception_preprocess)\n",
    "elif model_name == 'InceptionV3':\n",
    "    model = build_model(InceptionV3, inception_preprocess)\n",
    "elif model_name == 'EfficientNetB0':\n",
    "    model = build_model(EfficientNetB0, efficientnet_preprocess)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc442d9-c733-4d54-9a24-c81875e47996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 453ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.81      0.89      0.85       214\n",
      "          CI       0.90      0.95      0.92       518\n",
      "          CN       0.95      0.79      0.86       299\n",
      "\n",
      "    accuracy                           0.89      1031\n",
      "   macro avg       0.89      0.88      0.88      1031\n",
      "weighted avg       0.90      0.89      0.89      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1458762d-0958-4d7f-89bb-a39cb9e0a8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/rcmalli/keras-squeezenet.git\n",
      "  Cloning https://github.com/rcmalli/keras-squeezenet.git to c:\\users\\admin\\appdata\\local\\temp\\pip-req-build-ryxat59p\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Error [WinError 2] The system cannot find the file specified while executing command git version\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/rcmalli/keras-squeezenet.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0f585ae-f675-4eec-841c-44595b3bdc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-squeezenet in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.4)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras-squeezenet) (1.26.4)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras-squeezenet) (1.13.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras-squeezenet) (3.11.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras-squeezenet) (2.17.0)\n",
      "Requirement already satisfied: keras in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras-squeezenet) (3.5.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras-squeezenet) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras-squeezenet) (6.0.1)\n",
      "Requirement already satisfied: absl-py in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras->keras-squeezenet) (2.1.0)\n",
      "Requirement already satisfied: rich in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras->keras-squeezenet) (13.3.5)\n",
      "Requirement already satisfied: namex in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras->keras-squeezenet) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras->keras-squeezenet) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras->keras-squeezenet) (0.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\anaconda3\\lib\\site-packages (from keras->keras-squeezenet) (23.2)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow->keras-squeezenet) (2.17.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (4.25.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (69.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (2.17.1)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich->keras->keras-squeezenet) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from rich->keras->keras-squeezenet) (2.15.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (0.43.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras->keras-squeezenet) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow->keras-squeezenet) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-squeezenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3348d2bc-4aa3-47e0-b953-799d33f845ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 909ms/step - accuracy: 0.4632 - loss: 35.2224 - val_accuracy: 0.4879 - val_loss: 1.0439\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 908ms/step - accuracy: 0.5137 - loss: 1.0318 - val_accuracy: 0.4879 - val_loss: 1.0521\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 886ms/step - accuracy: 0.5067 - loss: 1.0355 - val_accuracy: 0.4879 - val_loss: 1.0411\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 885ms/step - accuracy: 0.5089 - loss: 1.0327 - val_accuracy: 0.4879 - val_loss: 1.0410\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 890ms/step - accuracy: 0.5070 - loss: 1.0338 - val_accuracy: 0.4879 - val_loss: 1.0414\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 886ms/step - accuracy: 0.5188 - loss: 1.0260 - val_accuracy: 0.4879 - val_loss: 1.0409\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 895ms/step - accuracy: 0.5054 - loss: 1.0345 - val_accuracy: 0.4879 - val_loss: 1.0439\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 891ms/step - accuracy: 0.5167 - loss: 1.0266 - val_accuracy: 0.4879 - val_loss: 1.0422\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 879ms/step - accuracy: 0.5073 - loss: 1.0314 - val_accuracy: 0.4879 - val_loss: 1.0429\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 968ms/step - accuracy: 0.5002 - loss: 1.0381 - val_accuracy: 0.4879 - val_loss: 1.0445\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 262ms/step - accuracy: 0.4800 - loss: 1.0518\n",
      "Validation Accuracy: 48.79%\n"
     ]
    }
   ],
   "source": [
    "#Alexnet\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset manually and split it into train/validation sets\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build AlexNet model\n",
    "def build_alexnet(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to build a simple SqueezeNet-like model\n",
    "def build_squeezenet(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Choose a model (you can switch between these models)\n",
    "model_name = 'AlexNet'  # Options: 'AlexNet', 'SqueezeNet', 'InceptionV3' (for GoogLeNet approximation)\n",
    "\n",
    "if model_name == 'AlexNet':\n",
    "    model = build_alexnet(IMG_SIZE + (3,), y_train.shape[1])\n",
    "elif model_name == 'SqueezeNet':\n",
    "    model = build_squeezenet(IMG_SIZE + (3,), y_train.shape[1])\n",
    "elif model_name == 'InceptionV3':  # Approximation for GoogLeNet\n",
    "    from tensorflow.keras.applications import InceptionV3\n",
    "    from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=IMG_SIZE + (3,)),\n",
    "        tf.keras.layers.Lambda(inception_preprocess),\n",
    "        InceptionV3(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,)),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c6d37ac-c229-4e53-a13f-e106f853e6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 266ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.00      0.00      0.00       220\n",
      "          CI       0.49      1.00      0.66       503\n",
      "          CN       0.00      0.00      0.00       308\n",
      "\n",
      "    accuracy                           0.49      1031\n",
      "   macro avg       0.16      0.33      0.22      1031\n",
      "weighted avg       0.24      0.49      0.32      1031\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef4a87e1-7862-4bc0-91f2-6aad406dbb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 3s/step - accuracy: 0.6047 - loss: 0.8715 - val_accuracy: 0.5655 - val_loss: 3.4789\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 3s/step - accuracy: 0.9104 - loss: 0.2582 - val_accuracy: 0.3317 - val_loss: 5.2078\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 3s/step - accuracy: 0.9464 - loss: 0.1511 - val_accuracy: 0.7682 - val_loss: 1.1675\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 3s/step - accuracy: 0.9661 - loss: 0.0987 - val_accuracy: 0.9331 - val_loss: 0.2088\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 3s/step - accuracy: 0.9792 - loss: 0.0658 - val_accuracy: 0.7294 - val_loss: 1.4509\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 3s/step - accuracy: 0.9732 - loss: 0.0855 - val_accuracy: 0.6596 - val_loss: 2.0211\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 3s/step - accuracy: 0.9728 - loss: 0.0874 - val_accuracy: 0.9738 - val_loss: 0.0669\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 3s/step - accuracy: 0.9882 - loss: 0.0353 - val_accuracy: 0.9709 - val_loss: 0.0945\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 3s/step - accuracy: 0.9832 - loss: 0.0581 - val_accuracy: 0.7808 - val_loss: 0.9306\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m450s\u001b[0m 3s/step - accuracy: 0.9904 - loss: 0.0313 - val_accuracy: 0.8681 - val_loss: 0.4458\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 898ms/step - accuracy: 0.8644 - loss: 0.4912\n",
      "Validation Accuracy: 86.81%\n"
     ]
    }
   ],
   "source": [
    "#Googlenet\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset manually and split it into train/validation sets\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build AlexNet model\n",
    "def build_alexnet(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to build a simple SqueezeNet-like model\n",
    "def build_squeezenet(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Choose a model (you can switch between these models)\n",
    "model_name = 'InceptionV3'  # Options: 'AlexNet', 'SqueezeNet', 'InceptionV3' (for GoogLeNet approximation)\n",
    "\n",
    "if model_name == 'AlexNet':\n",
    "    model = build_alexnet(IMG_SIZE + (3,), y_train.shape[1])\n",
    "elif model_name == 'SqueezeNet':\n",
    "    model = build_squeezenet(IMG_SIZE + (3,), y_train.shape[1])\n",
    "elif model_name == 'InceptionV3':  # Approximation for GoogLeNet\n",
    "    from tensorflow.keras.applications import InceptionV3\n",
    "    from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=IMG_SIZE + (3,)),\n",
    "        tf.keras.layers.Lambda(inception_preprocess),\n",
    "        InceptionV3(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,)),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a224a16f-3981-4a9a-9a10-d9d8d5425e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 968ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.64      1.00      0.78       218\n",
      "          CI       1.00      0.82      0.90       521\n",
      "          CN       0.97      0.86      0.91       292\n",
      "\n",
      "    accuracy                           0.87      1031\n",
      "   macro avg       0.87      0.89      0.86      1031\n",
      "weighted avg       0.91      0.87      0.88      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7c9ecb-db72-4f53-a89a-db840464a77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 820ms/step - accuracy: 0.4989 - loss: 23.2016 - val_accuracy: 0.6557 - val_loss: 0.7640\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 864ms/step - accuracy: 0.7805 - loss: 0.5726 - val_accuracy: 0.9030 - val_loss: 0.2594\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 877ms/step - accuracy: 0.9086 - loss: 0.2342 - val_accuracy: 0.9350 - val_loss: 0.1945\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 869ms/step - accuracy: 0.9642 - loss: 0.1094 - val_accuracy: 0.9447 - val_loss: 0.1665\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 875ms/step - accuracy: 0.9681 - loss: 0.0967 - val_accuracy: 0.9942 - val_loss: 0.0365\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 857ms/step - accuracy: 0.9844 - loss: 0.0466 - val_accuracy: 0.9922 - val_loss: 0.0287\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 876ms/step - accuracy: 0.9860 - loss: 0.0379 - val_accuracy: 0.9864 - val_loss: 0.0627\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 918ms/step - accuracy: 0.9971 - loss: 0.0124 - val_accuracy: 0.9845 - val_loss: 0.0366\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 879ms/step - accuracy: 0.9988 - loss: 0.0069 - val_accuracy: 0.9903 - val_loss: 0.0412\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 910ms/step - accuracy: 0.9868 - loss: 0.0352 - val_accuracy: 0.9709 - val_loss: 0.0955\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 240ms/step - accuracy: 0.9744 - loss: 0.0992\n",
      "Validation Accuracy: 97.09%\n"
     ]
    }
   ],
   "source": [
    "#Squeezenet\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset manually and split it into train/validation sets\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build AlexNet model\n",
    "def build_alexnet(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(96, kernel_size=(11, 11), strides=4, activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(5, 5), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(384, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3), strides=2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(4096, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Function to build a simple SqueezeNet-like model\n",
    "def build_squeezenet(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "        MaxPooling2D(pool_size=(3, 3)),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Choose a model (you can switch between these models)\n",
    "model_name = 'SqueezeNet'  # Options: 'AlexNet', 'SqueezeNet', 'InceptionV3' (for GoogLeNet approximation)\n",
    "\n",
    "if model_name == 'AlexNet':\n",
    "    model = build_alexnet(IMG_SIZE + (3,), y_train.shape[1])\n",
    "elif model_name == 'SqueezeNet':\n",
    "    model = build_squeezenet(IMG_SIZE + (3,), y_train.shape[1])\n",
    "elif model_name == 'InceptionV3':  # Approximation for GoogLeNet\n",
    "    from tensorflow.keras.applications import InceptionV3\n",
    "    from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=IMG_SIZE + (3,)),\n",
    "        tf.keras.layers.Lambda(inception_preprocess),\n",
    "        InceptionV3(weights='imagenet', include_top=False, input_shape=IMG_SIZE + (3,)),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52626dc7-e33e-4ebc-8e8a-8e55dc1ea830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 228ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       0.94      0.99      0.96       227\n",
      "          CI       1.00      0.95      0.97       509\n",
      "          CN       0.96      0.99      0.97       295\n",
      "\n",
      "    accuracy                           0.97      1031\n",
      "   macro avg       0.96      0.98      0.97      1031\n",
      "weighted avg       0.97      0.97      0.97      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa678ed7-564a-461d-a09f-3da984479c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m664s\u001b[0m 5s/step - accuracy: 0.5445 - loss: 0.9523 - val_accuracy: 0.6857 - val_loss: 0.6832\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m637s\u001b[0m 5s/step - accuracy: 0.7812 - loss: 0.5737 - val_accuracy: 0.7420 - val_loss: 0.6287\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m639s\u001b[0m 5s/step - accuracy: 0.8565 - loss: 0.3788 - val_accuracy: 0.8836 - val_loss: 0.3031\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 4s/step - accuracy: 0.9256 - loss: 0.2087 - val_accuracy: 0.9176 - val_loss: 0.2058\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 4s/step - accuracy: 0.9611 - loss: 0.1271 - val_accuracy: 0.9273 - val_loss: 0.1987\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 4s/step - accuracy: 0.9850 - loss: 0.0634 - val_accuracy: 0.9418 - val_loss: 0.1494\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 4s/step - accuracy: 0.9710 - loss: 0.0859 - val_accuracy: 0.9631 - val_loss: 0.0981\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 4s/step - accuracy: 0.9955 - loss: 0.0275 - val_accuracy: 0.9641 - val_loss: 0.0976\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 4s/step - accuracy: 0.9976 - loss: 0.0197 - val_accuracy: 0.9680 - val_loss: 0.0819\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 4s/step - accuracy: 0.9990 - loss: 0.0109 - val_accuracy: 0.9709 - val_loss: 0.0702\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 3s/step - accuracy: 0.9687 - loss: 0.0668\n",
      "Validation Accuracy: 97.09%\n"
     ]
    }
   ],
   "source": [
    "#VGG16+LSTM\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, GlobalAveragePooling2D, TimeDistributed, Flatten\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset manually and split it into train/validation sets\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build and compile a model with LSTM or BiLSTM\n",
    "def build_model_lstm(base_model_fn, preprocess_fn, lstm_type='LSTM', img_size=IMG_SIZE, timesteps=1):\n",
    "    # Load the pre-trained model (e.g., VGG16)\n",
    "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=img_size + (3,))\n",
    "    \n",
    "    # Freeze the pre-trained model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=img_size + (3,)),\n",
    "        tf.keras.layers.Lambda(preprocess_fn),  # Preprocessing specific to the model\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),  # Extract features from the CNN\n",
    "        Reshape((timesteps, -1)),  # Reshape to (timesteps, features) for LSTM input\n",
    "        \n",
    "        # LSTM or BiLSTM layer based on the choice\n",
    "        LSTM(128, return_sequences=False) if lstm_type == 'LSTM' else Bidirectional(LSTM(128, return_sequences=False)),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Choose a pre-trained model (using VGG16 for feature extraction)\n",
    "model_name = 'VGG16'\n",
    "\n",
    "# Choose LSTM or BiLSTM\n",
    "lstm_type = 'LSTM'  # Options: 'LSTM', 'BiLSTM'\n",
    "\n",
    "if model_name == 'VGG16':\n",
    "    if lstm_type == 'LSTM':\n",
    "        model = build_model_lstm(VGG16, vgg16_preprocess, lstm_type='LSTM')\n",
    "    elif lstm_type == 'BiLSTM':\n",
    "        model = build_model_lstm(VGG16, vgg16_preprocess, lstm_type='BiLSTM')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0d9ea04-5cc4-4a03-878c-9a9173868db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 3s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       1.00      0.91      0.95       230\n",
      "          CI       0.97      0.99      0.98       525\n",
      "          CN       0.95      0.99      0.97       276\n",
      "\n",
      "    accuracy                           0.97      1031\n",
      "   macro avg       0.97      0.96      0.97      1031\n",
      "weighted avg       0.97      0.97      0.97      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c67faed0-3706-4b29-8a88-8a3f32896e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5154 images belonging to 3 classes.\n",
      "['AD', 'CI', 'CN']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m489s\u001b[0m 4s/step - accuracy: 0.5319 - loss: 0.9574 - val_accuracy: 0.7488 - val_loss: 0.6539\n",
      "Epoch 2/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 4s/step - accuracy: 0.7869 - loss: 0.5555 - val_accuracy: 0.8371 - val_loss: 0.4129\n",
      "Epoch 3/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m446s\u001b[0m 3s/step - accuracy: 0.9096 - loss: 0.2855 - val_accuracy: 0.9214 - val_loss: 0.2265\n",
      "Epoch 4/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 4s/step - accuracy: 0.9451 - loss: 0.1616 - val_accuracy: 0.9612 - val_loss: 0.1358\n",
      "Epoch 5/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m504s\u001b[0m 4s/step - accuracy: 0.9777 - loss: 0.0828 - val_accuracy: 0.9661 - val_loss: 0.0948\n",
      "Epoch 6/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m508s\u001b[0m 4s/step - accuracy: 0.9839 - loss: 0.0570 - val_accuracy: 0.9428 - val_loss: 0.1282\n",
      "Epoch 7/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m472s\u001b[0m 4s/step - accuracy: 0.9806 - loss: 0.0665 - val_accuracy: 0.9205 - val_loss: 0.1734\n",
      "Epoch 8/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m477s\u001b[0m 4s/step - accuracy: 0.9793 - loss: 0.0585 - val_accuracy: 0.9728 - val_loss: 0.0863\n",
      "Epoch 9/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m471s\u001b[0m 4s/step - accuracy: 0.9904 - loss: 0.0335 - val_accuracy: 0.9360 - val_loss: 0.1814\n",
      "Epoch 10/10\n",
      "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 4s/step - accuracy: 0.9934 - loss: 0.0207 - val_accuracy: 0.9932 - val_loss: 0.0331\n",
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 3s/step - accuracy: 0.9917 - loss: 0.0361\n",
      "Validation Accuracy: 99.32%\n"
     ]
    }
   ],
   "source": [
    "#VGG16+Bilstm\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg16_preprocess\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, GlobalAveragePooling2D, TimeDistributed, Flatten\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "# Set the dataset directory\n",
    "dataset_dir = r'D:\\MuTTu\\research\\AZD\\3class AD\\dataset\\dataset'\n",
    "\n",
    "# Image size for CNN models\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Load dataset manually and split it into train/validation sets\n",
    "def load_and_split_dataset(dataset_dir, test_size=0.2):\n",
    "    datagen = ImageDataGenerator(preprocessing_function=None)\n",
    "    data_generator = datagen.flow_from_directory(\n",
    "        dataset_dir,\n",
    "        target_size=IMG_SIZE,  # Image size as per the pre-trained model\n",
    "        batch_size=1,  # Load one image at a time\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    "    \n",
    "    images, labels = [], []\n",
    "    \n",
    "    # Loop over the entire dataset and load images one by one\n",
    "    for i in range(len(data_generator)):\n",
    "        img, lbl = next(data_generator)  # Using next() function to get image and label\n",
    "        images.append(img[0])  # Append the first (and only) image in the batch\n",
    "        labels.append(lbl[0])  # Append the first (and only) label in the batch\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    # Split dataset into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Get class names\n",
    "    class_names = list(data_generator.class_indices.keys())\n",
    "    \n",
    "    # Return training data, validation data, and class names\n",
    "    return X_train, X_val, y_train, y_val, class_names\n",
    "\n",
    "# Load and split dataset\n",
    "X_train, X_val, y_train, y_val, class_names = load_and_split_dataset(dataset_dir)\n",
    "\n",
    "# Ensure class_names is correctly returned and stored\n",
    "print(class_names)  # This will print the class names to verify\n",
    "\n",
    "# Function to build and compile a model with LSTM or BiLSTM\n",
    "def build_model_lstm(base_model_fn, preprocess_fn, lstm_type='LSTM', img_size=IMG_SIZE, timesteps=1):\n",
    "    # Load the pre-trained model (e.g., VGG16)\n",
    "    base_model = base_model_fn(weights='imagenet', include_top=False, input_shape=img_size + (3,))\n",
    "    \n",
    "    # Freeze the pre-trained model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build the model\n",
    "    model = Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=img_size + (3,)),\n",
    "        tf.keras.layers.Lambda(preprocess_fn),  # Preprocessing specific to the model\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),  # Extract features from the CNN\n",
    "        Reshape((timesteps, -1)),  # Reshape to (timesteps, features) for LSTM input\n",
    "        \n",
    "        # LSTM or BiLSTM layer based on the choice\n",
    "        LSTM(128, return_sequences=False) if lstm_type == 'LSTM' else Bidirectional(LSTM(128, return_sequences=False)),\n",
    "        \n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Choose a pre-trained model (using VGG16 for feature extraction)\n",
    "model_name = 'VGG16'\n",
    "\n",
    "# Choose LSTM or BiLSTM\n",
    "lstm_type = 'BiLSTM'  # Options: 'LSTM', 'BiLSTM'\n",
    "\n",
    "if model_name == 'VGG16':\n",
    "    if lstm_type == 'LSTM':\n",
    "        model = build_model_lstm(VGG16, vgg16_preprocess, lstm_type='LSTM')\n",
    "    elif lstm_type == 'BiLSTM':\n",
    "        model = build_model_lstm(VGG16, vgg16_preprocess, lstm_type='BiLSTM')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_acc = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {val_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7500a8ae-5c6a-42a1-8daa-997203e9d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 3s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AD       1.00      0.99      0.99       244\n",
      "          CI       0.99      1.00      0.99       511\n",
      "          CN       0.99      0.99      0.99       276\n",
      "\n",
      "    accuracy                           0.99      1031\n",
      "   macro avg       0.99      0.99      0.99      1031\n",
      "weighted avg       0.99      0.99      0.99      1031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_prob = model.predict(X_val)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_val_pred = np.argmax(y_val_pred_prob, axis=1)\n",
    "y_val_true = np.argmax(y_val, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_val_true, y_val_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5492ea36-0877-40ce-ab12-1cbcc182b4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
